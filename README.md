# Titanic Machine Learning Project

## Model Performance
```
============================================================
      TITANIC ULTIMATE LEADERBOARD (ALL MODELS)
============================================================
Model Name                     | Accuracy   | Std Dev   
------------------------------------------------------------
Logistic Regression            | 0.8137     | 0.0280
Support Vector Machine         | 0.8316     | 0.0192
Random Forest                  | 0.8384     | 0.0326
XGBoost                        | 0.8418     | 0.0332
LightGBM                       | 0.8339     | 0.0274
CatBoost                       | 0.8417     | 0.0281
------------------------------------------------------------
Winner: XGBoost with 0.8418
```

**Note:** The 'Voting Ensemble' combines the mathematical strengths of all 4 models to reduce variance/errors.

## Citation
```bibtex
@misc{titanic,
    author = {Aidan Colvin},
    title = {Titanic - Machine Learning from Disaster},
    year = {2026},
    howpublished = {\url{https://kaggle.com/competitions/titanic}},
    note = {Kaggle}
}
```
